# -*- coding: utf-8 -*-
"""nn_tensorflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r_2N9bwzo2HXVFb2i7F0mPLrLIyzaW1o
"""

import numpy as np
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

# Load MNIST Dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Flatten 28x28 images into 784 input neurons
x_train = x_train.reshape(x_train.shape[0], 784).astype('float32') / 255
x_test = x_test.reshape(x_test.shape[0], 784).astype('float32') / 255

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Build a simple neural network model
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784,)))  # Hidden layer
model.add(Dense(10, activation='softmax'))  # Output layer for digits 0-9

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model for 10 epochs
model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Test the model on unseen data
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_accuracy * 100:.2f}%")